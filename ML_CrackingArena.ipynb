{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning - D1 CrackingArena**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>dataset</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'll check</td>\n",
       "      <td>D1CrackingArena</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I used to think this Putin was a bad man until...</td>\n",
       "      <td>D1CrackingArena</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Android Os - suck</td>\n",
       "      <td>D1CrackingArena</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>check this thread before applying: Apply For C...</td>\n",
       "      <td>D1CrackingArena</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy birthday have a nice day</td>\n",
       "      <td>D1CrackingArena</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content          dataset label\n",
       "0                                         I'll check  D1CrackingArena    NO\n",
       "1  I used to think this Putin was a bad man until...  D1CrackingArena    NO\n",
       "2                                  Android Os - suck  D1CrackingArena    NO\n",
       "3  check this thread before applying: Apply For C...  D1CrackingArena    NO\n",
       "4                     Happy birthday have a nice day  D1CrackingArena    NO"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D1CrackingArena.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'll check</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I used to think this Putin was a bad man until...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Android Os - suck</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>check this thread before applying: Apply For C...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy birthday have a nice day</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content label\n",
       "0                                         I'll check    NO\n",
       "1  I used to think this Putin was a bad man until...    NO\n",
       "2                                  Android Os - suck    NO\n",
       "3  check this thread before applying: Apply For C...    NO\n",
       "4                     Happy birthday have a nice day    NO"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['dataset'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Text Normalisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ill check</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i used to think this putin was a bad man until...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>android os suck</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>check this thread before applying apply for cr...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy birthday have a nice day</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content label\n",
       "0                                          ill check    NO\n",
       "1  i used to think this putin was a bad man until...    NO\n",
       "2                                    android os suck    NO\n",
       "3  check this thread before applying apply for cr...    NO\n",
       "4                     happy birthday have a nice day    NO"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)     # Remove links\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)                 # Remove special characters and numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()                # Remove extra spaces\n",
    "    return text.lower()                                     # Convert to lowercase\n",
    "\n",
    "df['content'] = df['content'].apply(normalize_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Stopwords Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Tokenisation and Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ill check</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>used think putin bad man ravishing russian man...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>android o suck</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>check thread applying apply cracker rank</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy birthday nice day</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content label\n",
       "0                                          ill check    NO\n",
       "1  used think putin bad man ravishing russian man...    NO\n",
       "2                                     android o suck    NO\n",
       "3           check thread applying apply cracker rank    NO\n",
       "4                            happy birthday nice day    NO"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(x)]))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1345\n",
      "Testing set size: 337\n"
     ]
    }
   ],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1000)  # Limit vocabulary size\n",
    "\n",
    "# Convert text to feature vectors\n",
    "X = vectorizer.fit_transform(df['content']).toarray()\n",
    "y = df['label']  # Target variable\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split dataset into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1 - Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       312\n",
      "           1       0.25      0.14      0.18         7\n",
      "           2       0.40      0.33      0.36        18\n",
      "\n",
      "    accuracy                           0.92       337\n",
      "   macro avg       0.53      0.48      0.50       337\n",
      "weighted avg       0.91      0.92      0.91       337\n",
      "\n",
      "Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Naive Bayes Performance:\")\n",
    "print(classification_report(y_test, nb_predictions))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, nb_predictions):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2 - Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       312\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.28      0.39      0.33        18\n",
      "\n",
      "    accuracy                           0.89       337\n",
      "   macro avg       0.41      0.44      0.42       337\n",
      "weighted avg       0.90      0.89      0.89       337\n",
      "\n",
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"SVM Performance:\")\n",
    "print(classification_report(y_test, svm_predictions))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, svm_predictions):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3 - Random Forest (RF)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       312\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.91       337\n",
      "   macro avg       0.31      0.33      0.32       337\n",
      "weighted avg       0.86      0.91      0.89       337\n",
      "\n",
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Random Forest Performance:\")\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rf_predictions):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4 - Extreme Gradient Boosting (XGBoost)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       312\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.60      0.33      0.43        18\n",
      "\n",
      "    accuracy                           0.93       337\n",
      "   macro avg       0.52      0.44      0.46       337\n",
      "weighted avg       0.91      0.93      0.92       337\n",
      "\n",
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train XGBoost model\n",
    "xgb_model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"XGBoost Performance:\")\n",
    "print(classification_report(y_test, xgb_predictions))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, xgb_predictions):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Performance Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model  Accuracy\n",
      "0    Naive Bayes  0.919881\n",
      "1            SVM  0.890208\n",
      "2  Random Forest  0.913947\n",
      "3        XGBoost  0.925816\n"
     ]
    }
   ],
   "source": [
    "# Collect accuracy scores\n",
    "results = {\n",
    "    \"Model\": [\"Naive Bayes\", \"SVM\", \"Random Forest\", \"XGBoost\"],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_score(y_test, nb_predictions),\n",
    "        accuracy_score(y_test, svm_predictions),\n",
    "        accuracy_score(y_test, rf_predictions),\n",
    "        accuracy_score(y_test, xgb_predictions),\n",
    "    ],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1 - Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best parameters for Naive Bayes: {'alpha': 2.0}\n",
      "Naive Bayes Performance after Hyperparameter Tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       312\n",
      "           1       0.25      0.14      0.18         7\n",
      "           2       0.45      0.28      0.34        18\n",
      "\n",
      "    accuracy                           0.93       337\n",
      "   macro avg       0.55      0.47      0.50       337\n",
      "weighted avg       0.91      0.93      0.92       337\n",
      "\n",
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes hyperparameter grid\n",
    "nb_param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 1.5, 2.0]  # Smoothing parameter\n",
    "}\n",
    "\n",
    "# Initialize Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# GridSearchCV for Naive Bayes\n",
    "nb_grid_search = GridSearchCV(estimator=nb_model, param_grid=nb_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "nb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(f\"Best parameters for Naive Bayes: {nb_grid_search.best_params_}\")\n",
    "best_nb_model = nb_grid_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "nb_predictions_tuned = best_nb_model.predict(X_test)\n",
    "print(\"Naive Bayes Performance after Hyperparameter Tuning:\")\n",
    "print(classification_report(y_test, nb_predictions_tuned))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, nb_predictions_tuned):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2 - Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters for SVM: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "SVM Performance after Hyperparameter Tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       312\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.92       337\n",
      "   macro avg       0.31      0.33      0.32       337\n",
      "weighted avg       0.86      0.92      0.89       337\n",
      "\n",
      "Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# SVM hyperparameter grid\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Initialize SVM model\n",
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "# GridSearchCV for SVM\n",
    "svm_grid_search = GridSearchCV(estimator=svm_model, param_grid=svm_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "svm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(f\"Best parameters for SVM: {svm_grid_search.best_params_}\")\n",
    "best_svm_model = svm_grid_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "svm_predictions_tuned = best_svm_model.predict(X_test)\n",
    "print(\"SVM Performance after Hyperparameter Tuning:\")\n",
    "print(classification_report(y_test, svm_predictions_tuned))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, svm_predictions_tuned):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3 - Random Forest (RF)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best parameters for Random Forest: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest Performance after Hyperparameter Tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       312\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.92       337\n",
      "   macro avg       0.31      0.33      0.32       337\n",
      "weighted avg       0.86      0.92      0.89       337\n",
      "\n",
      "Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Random Forest hyperparameter grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# GridSearchCV for Random Forest\n",
    "rf_grid_search = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(f\"Best parameters for Random Forest: {rf_grid_search.best_params_}\")\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "rf_predictions_tuned = best_rf_model.predict(X_test)\n",
    "print(\"Random Forest Performance after Hyperparameter Tuning:\")\n",
    "print(classification_report(y_test, rf_predictions_tuned))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rf_predictions_tuned):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4 - Extreme Gradient Boosting (XGBoost)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Best parameters for XGBoost: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.8}\n",
      "XGBoost Performance after Hyperparameter Tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       312\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.70      0.39      0.50        18\n",
      "\n",
      "    accuracy                           0.93       337\n",
      "   macro avg       0.55      0.46      0.49       337\n",
      "weighted avg       0.91      0.93      0.92       337\n",
      "\n",
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# XGBoost hyperparameter grid\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "\n",
    "# GridSearchCV for XGBoost\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_model, param_grid=xgb_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(f\"Best parameters for XGBoost: {xgb_grid_search.best_params_}\")\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "xgb_predictions_tuned = best_xgb_model.predict(X_test)\n",
    "print(\"XGBoost Performance after Hyperparameter Tuning:\")\n",
    "print(classification_report(y_test, xgb_predictions_tuned))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, xgb_predictions_tuned):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Performance Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model  Accuracy\n",
      "0    Naive Bayes  0.925816\n",
      "1            SVM  0.916914\n",
      "2  Random Forest  0.916914\n",
      "3        XGBoost  0.934718\n"
     ]
    }
   ],
   "source": [
    "# Collect accuracy scores after tuning\n",
    "tuned_results = {\n",
    "    \"Model\": [\"Naive Bayes\", \"SVM\", \"Random Forest\", \"XGBoost\"],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_score(y_test, nb_predictions_tuned),\n",
    "        accuracy_score(y_test, svm_predictions_tuned),\n",
    "        accuracy_score(y_test, rf_predictions_tuned),\n",
    "        accuracy_score(y_test, xgb_predictions_tuned),\n",
    "    ],\n",
    "}\n",
    "\n",
    "tuned_results_df = pd.DataFrame(tuned_results)\n",
    "print(tuned_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
