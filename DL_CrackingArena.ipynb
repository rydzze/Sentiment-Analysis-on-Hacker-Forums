{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Learning - D1 CrackingArena**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>dataset</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'll check</td>\n",
       "      <td>D1CrackingArena</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I used to think this Putin was a bad man until...</td>\n",
       "      <td>D1CrackingArena</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Android Os - suck</td>\n",
       "      <td>D1CrackingArena</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>check this thread before applying: Apply For C...</td>\n",
       "      <td>D1CrackingArena</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy birthday have a nice day</td>\n",
       "      <td>D1CrackingArena</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content          dataset label\n",
       "0                                         I'll check  D1CrackingArena    NO\n",
       "1  I used to think this Putin was a bad man until...  D1CrackingArena    NO\n",
       "2                                  Android Os - suck  D1CrackingArena    NO\n",
       "3  check this thread before applying: Apply For C...  D1CrackingArena    NO\n",
       "4                     Happy birthday have a nice day  D1CrackingArena    NO"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D1CrackingArena.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'll check</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I used to think this Putin was a bad man until...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Android Os - suck</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>check this thread before applying: Apply For C...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy birthday have a nice day</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content label\n",
       "0                                         I'll check    NO\n",
       "1  I used to think this Putin was a bad man until...    NO\n",
       "2                                  Android Os - suck    NO\n",
       "3  check this thread before applying: Apply For C...    NO\n",
       "4                     Happy birthday have a nice day    NO"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['dataset'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Text Normalisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ill check</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i used to think this putin was a bad man until...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>android os suck</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>check this thread before applying apply for cr...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy birthday have a nice day</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content label\n",
       "0                                          ill check    NO\n",
       "1  i used to think this putin was a bad man until...    NO\n",
       "2                                    android os suck    NO\n",
       "3  check this thread before applying apply for cr...    NO\n",
       "4                     happy birthday have a nice day    NO"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)     # Remove links\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)                 # Remove special characters and numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()                # Remove extra spaces\n",
    "    return text.lower()                                     # Convert to lowercase\n",
    "\n",
    "df['content'] = df['content'].apply(normalize_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Stopwords Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Tokenisation and Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ill check</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>used think putin bad man ravishing russian man...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>android o suck</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>check thread applying apply cracker rank</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy birthday nice day</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content label\n",
       "0                                          ill check    NO\n",
       "1  used think putin bad man ravishing russian man...    NO\n",
       "2                                     android o suck    NO\n",
       "3           check thread applying apply cracker rank    NO\n",
       "4                            happy birthday nice day    NO"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(x)]))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1345\n",
      "Testing set size: 337\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer for text\n",
    "tokenizer = Tokenizer(num_words=10000)  # Use top 10,000 most frequent words\n",
    "tokenizer.fit_on_texts(df['content'])\n",
    "\n",
    "# Convert text to sequences\n",
    "X_seq = tokenizer.texts_to_sequences(df['content'])\n",
    "\n",
    "# Pad sequences for LSTM and CNN\n",
    "X_pad = pad_sequences(X_seq, padding='post', maxlen=100)  # Padding sequences to max length of 100 words\n",
    "y = df['label']  # Target variable\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split dataset into training and testing sets (80-20 split)\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train_dl)}\")\n",
    "print(f\"Testing set size: {len(X_test_dl)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1 - Bidirectional Long-Short Term Memory (Bi-LSTM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 667ms/step - accuracy: 0.7638 - loss: 0.5287 - val_accuracy: 0.9258 - val_loss: 0.3268\n",
      "Epoch 2/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 0.9114 - loss: 0.3300 - val_accuracy: 0.9169 - val_loss: 0.3190\n",
      "Epoch 3/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 442ms/step - accuracy: 0.9114 - loss: 0.2654 - val_accuracy: 0.8249 - val_loss: 0.3430\n",
      "Epoch 4/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 462ms/step - accuracy: 0.8832 - loss: -0.0015 - val_accuracy: 0.7982 - val_loss: 0.6471\n",
      "Epoch 5/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 420ms/step - accuracy: 0.8914 - loss: -0.5284 - val_accuracy: 0.8576 - val_loss: 0.7379\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.8517 - loss: 0.6012\n",
      "BiLSTM Model Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Build BiLSTM model\n",
    "bilstm_model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "bilstm_model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "\n",
    "# Bidirectional LSTM layer\n",
    "bilstm_model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "\n",
    "# Dense layer\n",
    "bilstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "bilstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "bilstm_history = bilstm_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl))\n",
    "\n",
    "# Evaluate the model\n",
    "bilstm_loss, bilstm_acc = bilstm_model.evaluate(X_test_dl, y_test_dl)\n",
    "print(f\"BiLSTM Model Accuracy: {bilstm_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2 - Convolutional Neural Network (CNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 139ms/step - accuracy: 0.7365 - loss: 0.5573 - val_accuracy: 0.9258 - val_loss: 0.3484\n",
      "Epoch 2/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9093 - loss: 0.3606 - val_accuracy: 0.9199 - val_loss: 0.3257\n",
      "Epoch 3/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9027 - loss: 0.3007 - val_accuracy: 0.8991 - val_loss: 0.2925\n",
      "Epoch 4/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.9063 - loss: 0.1745 - val_accuracy: 0.8665 - val_loss: 0.2767\n",
      "Epoch 5/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.8545 - loss: 0.0790 - val_accuracy: 0.8754 - val_loss: 0.2310\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8698 - loss: 0.2403\n",
      "CNN Model Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Build CNN model\n",
    "cnn_model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "cnn_model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "\n",
    "# Convolutional layer\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "\n",
    "# Max pooling layer\n",
    "cnn_model.add(MaxPooling1D(pool_size=4))\n",
    "\n",
    "# Global Max Pooling\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# Dense layer\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "cnn_history = cnn_model.fit(X_train_dl, y_train_dl, epochs=5, batch_size=64, validation_data=(X_test_dl, y_test_dl))\n",
    "\n",
    "# Evaluate the model\n",
    "cnn_loss, cnn_acc = cnn_model.evaluate(X_test_dl, y_test_dl)\n",
    "print(f\"CNN Model Accuracy: {cnn_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Performance Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM Model Accuracy: 0.86\n",
      "CNN Model Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Print both model's accuracy\n",
    "print(f\"BiLSTM Model Accuracy: {bilstm_acc:.2f}\")\n",
    "print(f\"CNN Model Accuracy: {cnn_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1 - Bidirectional Long-Short Term Memory (Bi-LSTM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter tuning function for BiLSTM model\n",
    "# def build_bilstm_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "    \n",
    "#     # Bidirectional LSTM layer with hyperparameters\n",
    "#     model.add(Bidirectional(LSTM(\n",
    "#         units=hp.Int('units', min_value=64, max_value=256, step=64),\n",
    "#         dropout=hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1),\n",
    "#         recurrent_dropout=hp.Float('recurrent_dropout', min_value=0.1, max_value=0.5, step=0.1)\n",
    "#     )))\n",
    "    \n",
    "#     # Dense layer\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#     # Compile model with dynamic learning rate\n",
    "#     model.compile(\n",
    "#         loss='binary_crossentropy',\n",
    "#         optimizer=tf.keras.optimizers.Adam(\n",
    "#             learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log')\n",
    "#         ),\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "#     return model\n",
    "\n",
    "# # Create a tuner for BiLSTM\n",
    "# bilstm_tuner = kt.Hyperband(\n",
    "#     build_bilstm_model,\n",
    "#     objective='val_accuracy',\n",
    "#     max_epochs=5,\n",
    "#     factor=3,\n",
    "#     directory='bilstm_tuner',\n",
    "#     project_name='bilstm_hyperparam_tuning'\n",
    "# )\n",
    "\n",
    "# # Start hyperparameter tuning\n",
    "# bilstm_tuner.search(X_train_dl, y_train_dl, epochs=5, validation_data=(X_test_dl, y_test_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2 - Convolutional Neural Network (CNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter tuning function for CNN model\n",
    "# def build_cnn_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "    \n",
    "#     # Convolutional layer with hyperparameters\n",
    "#     model.add(Conv1D(\n",
    "#         filters=hp.Int('filters', min_value=64, max_value=256, step=64),\n",
    "#         kernel_size=hp.Int('kernel_size', min_value=3, max_value=7, step=1),\n",
    "#         activation='relu'\n",
    "#     ))\n",
    "    \n",
    "#     # MaxPooling layer\n",
    "#     model.add(MaxPooling1D(pool_size=4))\n",
    "    \n",
    "#     # Global Max Pooling\n",
    "#     model.add(GlobalMaxPooling1D())\n",
    "    \n",
    "#     # Dense layer\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#     # Compile model with dynamic learning rate\n",
    "#     model.compile(\n",
    "#         loss='binary_crossentropy',\n",
    "#         optimizer=tf.keras.optimizers.Adam(\n",
    "#             learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log')\n",
    "#         ),\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "#     return model\n",
    "\n",
    "# # Create a tuner for CNN\n",
    "# cnn_tuner = kt.Hyperband(\n",
    "#     build_cnn_model,\n",
    "#     objective='val_accuracy',\n",
    "#     max_epochs=5,\n",
    "#     factor=3,\n",
    "#     directory='cnn_tuner',\n",
    "#     project_name='cnn_hyperparam_tuning'\n",
    "# )\n",
    "\n",
    "# # Start hyperparameter tuning\n",
    "# cnn_tuner.search(X_train_dl, y_train_dl, epochs=5, validation_data=(X_test_dl, y_test_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Performance Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the best BiLSTM model and evaluate\n",
    "# best_bilstm_model = bilstm_tuner.get_best_models(num_models=1)[0]\n",
    "# bilstm_loss, bilstm_acc = best_bilstm_model.evaluate(X_test_dl, y_test_dl)\n",
    "# print(f\"Best BiLSTM Model Accuracy: {bilstm_acc:.2f}\")\n",
    "\n",
    "# # Get the best CNN model and evaluate\n",
    "# best_cnn_model = cnn_tuner.get_best_models(num_models=1)[0]\n",
    "# cnn_loss, cnn_acc = best_cnn_model.evaluate(X_test_dl, y_test_dl)\n",
    "# print(f\"Best CNN Model Accuracy: {cnn_acc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
